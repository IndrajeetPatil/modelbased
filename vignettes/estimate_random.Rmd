---
title: "How to use Mixed models to Estimate Individuals' Scores"
output: 
  rmarkdown::html_vignette:
    toc: true
    fig_width: 10.08
    fig_height: 6
tags: [r, estimate, mixed models]
vignette: >
  %\VignetteIndexEntry{How to use Mixed models to Estimate Individuals' Scores}
  \usepackage[utf8]{inputenc}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
bibliography: bibliography.bib
---

```{r message=FALSE, warning=FALSE, include=FALSE}
library(knitr)
options(knitr.kable.NA = "")
knitr::opts_chunk$set(comment = ">", dpi = 450)
options(digits = 2)

if (!requireNamespace("ggplot2", quietly = TRUE) ||
  !requireNamespace("see", quietly = TRUE) ||
  !requireNamespace("lme4", quietly = TRUE) ||
  !requireNamespace("parameters", quietly = TRUE) ||
  !requireNamespace("dplyr", quietly = TRUE)) {
  knitr::opts_chunk$set(eval = FALSE)
}

set.seed(333)
```


Mixed models are powerful tools that can be used for a variety of interesting purposes. Indeed, while they are typically used to be more accurate and resilient in estimating population-level effects (aka the "fixed" effects), they can also be used to gain insight into group-level (i.e., individuals' level scores, if the random factors are individuals) variability.

For this practical walkthrough, we will use the **Speed-Accuracy Data** (Wagenmakers, Ratcliff, Gomez, \& McKoon, 2008) from the `rtdists` package, in which 17 participants (the **id** variable) performed some reaction time (RT) experiment under two conditions, speed and accuracy (the **condition** variable).

How hypotheses is that participants will be **faster** (i.e., lower RT) in the speed condition as compared to the accuracy condition. On the other hand, they will make less **errors** in the accuracy condition as compared to the speed condition.

In the following, we will load the necessary packages and clean the data by removing outliers and out-of-scope data.

```{r warning=FALSE, message=FALSE}
library(rtdists)
library(ggplot2)
library(dplyr)
library(lme4)
library(brms)
library(parameters)
library(modelbased)

data <- rtdists::speed_acc %>% 
  # Remove outliers &  Keep only word condition 
  filter(rt < 1.5,  
         stim_cat == "word",
         frequency == "low") %>% 
  # Add new 'error' column that is 1 if the response doesn't match the category
  mutate(error = ifelse(as.character(response) != as.character(stim_cat), 1, 0))
```

# Speed (RT) 

## Population-level Effects


For the reaction time, we will start by removing all the incorrect responses, since they are not reflective of a "successful" cognitive process. Then, and we will then plot the RT according to the condition and stimulus category.


```{r warning=FALSE, message=FALSE}
data_rt <- filter(data, error == 0)

ggplot(data = data_rt, aes(y = rt, condition)) + 
  geom_violin()
```

The descriptive visualisation indeed seems to suggest that people are slower in the **accuracy** condition as compared to the **speed** condition. And there could also be a slight effect of **frequency**. 

Let's verify that using the [**modelisation approach**](https://easystats.github.io/modelbased/articles/modelisation_approach.html).

```{r warning=FALSE, message=FALSE}
model <- lmer(rt ~ condition + (1 + condition | id) + (1 | stim), 
              data = data_rt)
```

Let's unpack the formula of this model. We're tying to predict `rt` using different terms. These can be separated into two groups, the *fixed* effects and the *random* effects. Having `condition` as a fixed effect means that we are interested in estimating the **"general"** effect of the condition, across all subjects and items (i.e., at the ***population level***). On top of that effect of condition, a second 'fixed' parameter was implicitly specified and will be estimated, the **intercept** (as you might know, one has to explicitly remove it through `rt ~ 0 + condition`, otherwise it is added automatically).

Let's investigate these two fixed parameters first:

```{r warning=FALSE, message=FALSE}
parameters(model, effects = "fixed")
```

Because `condition` is a factor with two levels, these parameters are easily interpretable. The *intercept* corresponds to the `rt` at the baseline level of the factor (accuracy), and the effect of condition corresponds to the change in `rt` between the intercept and the speed condition. In other words, the effect of `condition` refers to the difference between the two conditions, `speed - accuracy`. 

As we can see, this difference is significant, and people have, **in general**, a lower `rt` (the sign is negative) in the speed condition. 

Let's visualize the [marginal means](https://easystats.github.io/modelbased/articles/estimate_means.html) estimated by the model: 

```{r warning=FALSE, message=FALSE}
estimate_means(model) %>% 
  plot(show_data = "violin") 
```

Now, what's up with the **random effects**. In the formula, we specified random intercepts (i.e., the right part of the bar `|` symbol) for `id` (the participants) and `stim`. That means that **each participant and each stimulus will have its own "Intercept" parameter** (which, as we've seen before, corresponds to the `rt` in the accuracy condition). Additionally, we've specified the random effect ("random slope" - the left side of the bar) of `condition` for each participant. That means that **each participant will have its own effect of condition** computed.

## Group-level Effects

That's nice to know, but how to actually **get access** to these group-level scores.

```{r warning=FALSE, message=FALSE}
individual <- estimate_individual(model, indices = "Coefficient")
summary(individual)
```





# Accuracy



# Non-linear Model

# Scale-Location Model

# References

